\chapter{Results}\label{res:res}

\section{Centerline Extraction Experiments}

\subsection{Experiment I: MFlux in CAT08 Challenge}

Tables \ref{tb:tb_4_1},\ref{tb:tb_4_2} and \ref{tb:tb_4_3}  presents the results of the semi-automatic coronary centerline extraction on the CTA datasets submitted to the Web-based platform. The following average results were obtained. 

\begin{table*}[h]
\scriptsize
\caption{MFlux average overlap per dataset}
\centering
\begin{tabular}{|c|cc|cc|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Dataset}} &\multicolumn{2}{c|}{\textbf{OV}} &\multicolumn{2}{c|}{\textbf{OF}} &\multicolumn{2}{c|}{\textbf{OT}}\\
\multicolumn{1}{|c|}{\textbf{nr.}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
0&96.2&73.7&69.5&65.2&96.2&73.7\\
1&95.0&47.6&95.0&47.5&95.0&47.5\\
2&99.4&74.8&92.2&71.4&99.4&74.8\\
3&64.5&49.9&47.2&43.5&64.5&49.6\\
4&70.3&58.5&88.8&67.7&71.0&60.7\\
5&95.8&56.8&40.4&20.2&95.8&48.1\\
6&76.9&63.9&73.6&64.1&77.1&63.8\\
7&78.4&40.4&16.7&9.0&78.4&39.7\\
\hline
\textbf{Avg.}&\textbf{84.3}&\textbf{60.4}&\textbf{65.3}&\textbf{50.7}&\textbf{84.4}&\textbf{59.2}\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_1}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{MFlux average accuracy per dataset}
\centering
\begin{tabular}{|c|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Dataset}} &\multicolumn{2}{c|}{\textbf{AI}}\\
\multicolumn{1}{|c|}{\textbf{nr.}} &\multicolumn{1}{c|}{\textbf{mm}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
0&0.43&33.8\\
1&0.42&30.6\\
2&0.38&27.6\\
3&0.49&29.6\\
4&0.35&27.3\\
5&0.43&34.5\\
6&0.37&27.2\\
7&0.43&24.3\\
\hline
\textbf{Avg.}&\textbf{0.41}&\textbf{29.2}\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_2}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{MFlux Summary}
\centering
\begin{tabular}{|c|ccc|ccc|}
\hline
\multicolumn{1}{|c|}{\textbf{Measure}} &\multicolumn{3}{c|}{\textbf{\% / mm}} &\multicolumn{3}{c|}{\textbf{score}}  \\
\multicolumn{1}{|c|}{\textbf{}} &\multicolumn{1}{c|}{\textbf{min.}} &\multicolumn{1}{c|}{\textbf{max.}} &\multicolumn{1}{c|}{\textbf{avg.}} &\multicolumn{1}{c|}{\textbf{min.}} &\multicolumn{1}{c|}{\textbf{max.}} &\multicolumn{1}{c|}{\textbf{avg.}}\\
\hline
OV& 8.5\%&100.0\%&84.3\%& 5.8&100.0&60.4\\
OF&10.1\%&100.0\%&65.3\%& 5.0&100.0&50.7\\
OT& 8.5\%&100.0\%&84.4\%& 5.4&100.0&59.2\\
AI&0.28 mm&0.56 mm&0.41 mm&21.7&41.3&29.2\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_3}
\normalsize
\end{table*}

A 84.3\% overlap with expert human manual annotations was achieved, until the first failure (OF) 65.3\%, in clinically relevant segments (radius $>$ 1.5 mm, OT) 84.4\%. In terms of accuraccy within the vessel (AI) an average of 0.41 mm where obtained. Generally, the method ranks ninth in the overlaping section and 12$^{th}$ for the accuraccy rank in comparison with the CAT08 methods. Visual inspection revealed that most extraction errors occurred at the start of the vessel and near to the ostium. 

\subsection{Experiment II: MFlux in MICCAI2012 Challenge}

Since MICCAI12 does not provide the lumen radius annotations, only overlapping measures are taking into account in this section. Although, the experiment goal was the correct extraction in the problematic datasets. An overall good overlapping was achieved. This could be due to an improvement in the quality of images in the challenge.

\begin{table*}[h]
\scriptsize
\caption{Dataset 05, vessel 0 (RCA) VS reference team KLEB (Manually Corrected)}
\centering
\begin{tabular}{|c|cc|cc|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Methods}} &\multicolumn{2}{c|}{\textbf{OV}} &\multicolumn{2}{c|}{\textbf{OF}} &\multicolumn{2}{c|}{\textbf{OT}}\\
\multicolumn{1}{|c|}{\textbf{}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
G\&T (itkRGC)&99.0 &99.0 &99.0 &99.0&99.0&99.0\\
MFlux&98.67&74.83& 98.51&49.25& 98.50&71.64\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_7}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{Dataset 01, vessel 4 (L-PDA) VS reference team KLEB (Manually Corrected)}
\centering
\begin{tabular}{|c|cc|cc|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Methods}} &\multicolumn{2}{c|}{\textbf{OV}} &\multicolumn{2}{c|}{\textbf{OF}} &\multicolumn{2}{c|}{\textbf{OT}}\\
\multicolumn{1}{|c|}{\textbf{}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
G\&T (itkRGC)&100 &100&100 &100&100&100\\
MFlux&100&100& 100&100&100&100\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_7}
\normalsize
\end{table*}
	

\subsection{Experiment III: MFlux VS G\&T (itkRGC)}

Tables \ref{tb:tb_4_4},\ref{tb:tb_4_5} and \ref{tb:tb_4_6} give the results of G\&T implementation on the same CTA datasets. Also, table \ref{tb:tb_4_7} resume the performance of both methods against the best and worst CAT08 methods and the team results for this challenge.

\begin{table*}[h]
\scriptsize
\caption{G\&T average overlap per dataset}
\centering
\begin{tabular}{|c|cc|cc|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Dataset}} &\multicolumn{2}{c|}{\textbf{OV}} &\multicolumn{2}{c|}{\textbf{OF}} &\multicolumn{2}{c|}{\textbf{OT}}\\
\multicolumn{1}{|c|}{\textbf{nr.}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
0&91.5&46.7&64.6&38.5&91.5&46.7\\
1&100.0&100.0&100.0&100.0&100.0&100.0\\
2&98.2&61.9&88.7&58.3&98.1&61.8\\
3&71.1&56.7&70.6&67.4&71.1&52.9\\
4&91.3&69.1&91.7&69.2&93.5&72.1\\
5&92.9&50.6&44.9&22.5&92.9&46.6\\
6&81.6&65.8&84.0&67.0&83.2&79.1\\
7&48.2&25.2&49.5&25.7&48.2&24.3\\
\hline
\textbf{Avg.}&\textbf{84.4}&\textbf{57.8}&\textbf{73.8}&\textbf{54.2}&\textbf{84.9}&\textbf{59.4}\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_4}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{G\&T average accuracy per dataset}
\centering
\begin{tabular}{|c|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Dataset}} &\multicolumn{2}{c|}{\textbf{AI}}\\
\multicolumn{1}{|c|}{\textbf{nr.}} &\multicolumn{1}{c|}{\textbf{mm}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
0&0.45&30.6\\
1&0.46&28.9\\
2&0.40&25.3\\
3&0.46&32.2\\
4&0.35&25.8\\
5&0.40&37.1\\
6&0.35&29.5\\
7&0.39&32.0\\
\hline
\textbf{Avg.}&\textbf{0.40}&\textbf{30.1}\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_5}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{G\&T Summary}
\centering
\begin{tabular}{|c|ccc|ccc|}
\hline
\multicolumn{1}{|c|}{\textbf{Measure}} &\multicolumn{3}{c|}{\textbf{\% / mm}} &\multicolumn{3}{c|}{\textbf{score}}  \\
\multicolumn{1}{|c|}{\textbf{}} &\multicolumn{1}{c|}{\textbf{min.}} &\multicolumn{1}{c|}{\textbf{max.}} &\multicolumn{1}{c|}{\textbf{avg.}} &\multicolumn{1}{c|}{\textbf{min.}} &\multicolumn{1}{c|}{\textbf{max.}} &\multicolumn{1}{c|}{\textbf{avg.}}\\
\hline
OV&13.9\%&100.0\%&84.4\%& 9.0&100.0&57.8\\
OF& 9.6\%&100.0\%&73.8\%& 4.8&100.0&54.2\\
OT&13.9\%&100.0\%&84.9\%& 9.0&100.0&59.4\\
AI&0.27 mm&0.52 mm&0.40 mm&22.5&43.1&30.1\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_6}
\normalsize
\end{table*}

\begin{table*}[h]
\scriptsize
\caption{Quantitative methods comparison using CAT08 framework}
\centering
\begin{tabular}{|c|cc|cc|cc|cc|}
\hline
\multicolumn{1}{|c|}{\textbf{Methods}} &\multicolumn{2}{c|}{\textbf{OV}} &\multicolumn{2}{c|}{\textbf{OF}} &\multicolumn{2}{c|}{\textbf{OT}}&\multicolumn{2}{c|}{\textbf{AI}}\\
\multicolumn{1}{|c|}{\textbf{}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}} &\multicolumn{1}{c|}{\textbf{\%}} &\multicolumn{1}{c|}{\textbf{score}}&\multicolumn{1}{c|}{\textbf{mm}} &\multicolumn{1}{c|}{\textbf{score}}\\
\hline
Friman et al.&99.3 &91.6& 94.6 &83.2 &99.5 & 90.0 &0.24 &47.9\\
G\&T (itkRGC)&84.4&57.8&73.8&54.2&84.9&59.4&0.40&30.1\\
MFlux&84.3&60.4&65.3&50.7&84.4&59.2&0.41&29.3\\
Hern\'andez et al. &77.0& 40.5 &52.1 &31.5 & 79.0 &45.3 &0.41 &29.3 \\
Castro et al.&72.6 &38.9 &45.6 &27.3 &73.8 & 41.0 &0.67 &21.2\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_7}
\normalsize
\end{table*}

Despite our limited comparison in terms of vesselness filters, our method is able to track centerline vessels with an accuracy comparable to the experts and with similar G\&T performance.

\section{Supervised Learning Experiment in Lesion Detection}

Table \ref{tb:ml_res} shows the average results of our method and the others for stenosis dectection measures: sensitivity, specificity, positive predictive value, negative predictive value and accuracy. In general, our results are
worse than the literature performance \citep{Mittal2010,Zuluaga2011a}(specificity $>$ 75\% on CTA). Therefore, the ability of our method to discriminate significant calcifications from non-significant ones remains  limited (66\%). Nevertheless, as compared to the non imbalanced options in the same dataset (AdaBoost M1 and Random Forest), our method leads the list in terms of specificity, over the testing set (See Fig \ref{fig:errcurve}).

\begin{figure}[ht]
	\centering
		\includegraphics[width=0.5\textwidth]{./Figures/289Final.png}
	\caption[Classification Curve]{(\textit{Top}) Classification error curve.}
	\label{fig:errcurve}
\end{figure}


\begin{table*}[h]
\scriptsize
\caption{Quantitative learning performance}
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{\textbf{Methods}} &\multicolumn{1}{c|}{\textbf{Sens (\%)}} &\multicolumn{1}{c|}{\textbf{Spec (\%)}} &\multicolumn{1}{c|}{\textbf{PPV (\%)}}&\multicolumn{1}{c|}{\textbf{NPV (\%)}}&\multicolumn{1}{c|}{\textbf{Accu (\%)}}\\
\hline
AdaBoost M1&99.57 &59.55 &97.15 &90.99 &96.88 \\
\textbf{RUSBoost} &\textbf{98.84} &\textbf{66.29} &\textbf{97.59} &\textbf{80.55} &\textbf{96.65}\\
Random Forest&99.19 &52.81 &96.68 &82.46 &96.06\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:ml_res}
\normalsize
\end{table*}

An additional qualitative evaluation (See Fig \ref{fig:res_vis}) reveals that we detect the majority of lesions, but from the slice-based point view, we are highly penalized in terms of false negatives, since radiologists assume a bigger lesion size (affecting more consecutive slices). Future work in a multi-scale cylinder could give better results.
 
\begin{figure}[ht]
	\centering
		\includegraphics[width=0.7\textwidth]{./Figures/visual_lesions.png}
	\caption[Visual Assesment in Lesion Detection]{Visual comparison between reference data (green=healthy, red=calcified) and results data (cyan curve peaks).}
	\label{fig:res_vis}
\end{figure}