\chapter{Evaluation}\label{eval:eval}

\section{Introduction}


%This chapter will be mainly focuses on the most recent works in coronaries, specially the ones falling in the 3a group. Various axis extraction methods have been evaluated in~\citep{Metz2008} and demonstrated a high accuracy compared to reference axes. For this reason, even if it is still a hard task in terms of image processing, the results confirm the current feasibility of the assumption and the availability of a correct centerline for posterior processing tasks. In most of the cases, centerlines are also needed for posterior processing task such as stenosis detection and quantification.

\section{Materials}\label{eval:Materials}
 
The datasets were obtained from the publicly available Rotterdam Coronary Artery Algorithm Evaluation Framework (http://coronary.bigr.nl/). A total of twenty-six multi-center multi-vendor datasets were used for this study. Eight datasets from centerline extraction challenge, and the rest of them from the stenoses challenge. 
\begin{table*}
\scriptsize
\caption{Image quality of the CAT08 datasets and vessels}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{Image quality} &\multicolumn{1}{c|}{\textbf{Poor}} &\multicolumn{1}{c|}{\textbf{Moderate}} &\multicolumn{1}{c|}{\textbf{Good}}&\multicolumn{1}{c|}{\textbf{Total}}\\
\hline
\# of datasets&2 &3&3 &8\\
\# of vessels&8 &12&12 &32\\
\hline
\end{tabular}
\vspace{-0.3cm}
\label{tb:tb_4_5}
\normalsize
\end{table*}



For additional information about the image acquisition, data selection and reference standards, the reader may refer to ~\citep{Schaap2009} and KirisÌ§li et al. ~\citep{Kirisli2013} articles, or to the framework website.

\section{Evaluation Measures}

Four different measures (three for overlapping and one for accuraccy assesment) are used in this section. All of them are based on the terms defined by \citep{Schaap2009} (See \ref{fig:exp3_ms}).

\begin{figure}[htbp]
	\centering
		\includegraphics[width=1.0\textwidth]{./Figures/eval_ms.png}
	\caption[Coronary Centerline Evaluation Measures CAT08]{Evaluation Measures used at CAT08 (source: \citep{Schaap2009}).}
	\label{fig:exp3_ms}
\end{figure}

From the overlap point of view, overlap \textbf{(OV)} represents the ability to track the complete vessel annotated by the human observers; overlap until first error \textbf{(OF)} determines how much of a coronary artery has been extracted before making the first error; Finally, overlap with the clinically relevant part of the vessel \textbf{(OT)} gives an indication how the method is able to track a clinical relevant vessel section. An algorithm score of 100 points is a perfect match between us and the reference, a score equal to 0 is a total failure in the extraction. In the accuraccy side, average inside \textbf{(AI)} is the average distance inside the vessel, it uses the annotated radius to score it. The observer score equal to 50 points, say if we do better ($>$50 points) or worst ($<$50 points).

\section{Centerline Extraction Experiments}

Both quantitative and qualitative evaluations were conducted to assess the performance of the method. The quantitative evaluation provides an objective evaluation of the method and enables comparison with previously published methods. However, comparison with results in literature should always be done with care, as results have been obtained on different data sets. A limitation of quantitative evaluation is that it requires a set of manually annotated structures, which is time consuming and not feasible for large numbers of 3D data. Therefore, we also conducted qualitative evaluations, as they can be performed in less time and hence on a larger number of data. The quantitative and qualitative evaluation measures used in this work were introduced in the section above.

\subsection{Experiment I: MFlux in CAT08 Challenge}

The centerline experiments where done using the eight training datasets from CAT08 challenge. For each patient, four vessels are provided in separated files. Since the consensus centerlines (done by three observers) are available in this experiment with their inter-observer variability measures, a quantitative analysis was performed using the standard framework proposed by ~\citep{Schaap2009}. Also, dataset results have been sent to the Web-based evaluation framework in order to verify the method results.

\subsection{Experiment II: MFlux in MICCAI2012 Challenge}

During the ``Stenoses Detection, Quantification and Lumen Segmentation challenge'', our team failed extracting some  vessels in problematic images (dataset 01 and dataset 05). Therefore, a correct and complete extraction is mandatory with this new version. Figure \ref{fig:exp2_dt05} shows our new framework processing one of the problematic datasets (dataset 05).

\begin{figure}[htbp]
	\centering
		\includegraphics[width=4.0in]{./Figures/dt05v01.png}
		\includegraphics[width=4.0in]{./Figures/dt05v01_cpr.png}
	\caption[MICCAI2012 Extraction]{\textit{Top}, Interactive RCA vessel extraction (dataset 05) . \textit{Bottom}, CPR visualization of the vessel extracted.}
	\label{fig:exp2_dt05}
\end{figure}

\subsection{Experiment III: MFlux VS Gulsun \& Tek (itkRGC)}

In the third experiment, we investigate the robustness of our method against a new version of Gulsun \& Tek developed by our team at Creatis. The performance of the team implementation (Gulsun \& Tek) was evaluated on the same CAT08 datasets. An additional results submission was done to the Web-platform. Also, problematic datasets at MICCAI2012 were visually evaluated with the two implementations (MFlux, G \& T). Figure ~\ref{fig:exp3_cpr} shows an axe extracted by the methods against the reference.

\begin{figure}[htbp]
	\centering
		\includegraphics[width=4.0in]{./Figures/cpr_lkeb.png}
		\includegraphics[width=4.0in]{./Figures/cpr_gt.png}
		\includegraphics[width=4.0in]{./Figures/cpr_mflux.png}
	\caption[Centerline Comparison]{Centerline visual assesment between: \textit{Top}, MICCAI 2012 Reference. \textit{Middle}, G \& T axe. \textit{Bottom}, MFlux axe.}
	\label{fig:exp3_cpr}
\end{figure}

\section{Supervised Learning Experiments in Lesion Detection}

\subsection{Experiment I: RUSBoost in vessel hyphotesis}

\subsection{Experiment II: RUSBoost in segment hyphotesis}

\subsection{Experiment III: RUSBoost VS Random Forest}

